# demo_headpose_sixd.py
import os
import cv2
import mediapipe as mp

from src.headpose_sixd import SixDRepONNX
from src.visualize_utils import draw_headpose_axes

# ===== C·∫§U H√åNH ƒê∆Ø·ªúNG D·∫™N =====
IMG_PATH   = "data_test/sample_frames/Vid1_frame_00015.jpg"  # ho·∫∑c Vid1_frame_00015.jpg
ONNX_PATH  = "models/SixDRepNet.onnx"   # ƒë√∫ng t√™n file .onnx c·ªßa b·∫°n
OUT_PATH   = "data_test/sample_frames/headpose_sixd_demo2.jpg"


def detect_face_bbox_mediapipe(img_bgr):
    """
    D√≤ khu√¥n m·∫∑t b·∫±ng MediaPipe Face Detection, tr·∫£ v·ªÅ (x1,y1,x2,y2) ho·∫∑c None.
    """
    h, w = img_bgr.shape[:2]
    mp_fd = mp.solutions.face_detection.FaceDetection(
        model_selection=0,
        min_detection_confidence=0.6
    )

    rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)
    res = mp_fd.process(rgb)
    if not res.detections:
        return None

    det = res.detections[0]
    bb = det.location_data.relative_bounding_box

    x1 = int(bb.xmin * w)
    y1 = int(bb.ymin * h)
    x2 = int((bb.xmin + bb.width) * w)
    y2 = int((bb.ymin + bb.height) * h)

    # clamp
    x1 = max(0, min(w - 1, x1))
    y1 = max(0, min(h - 1, y1))
    x2 = max(0, min(w - 1, x2))
    y2 = max(0, min(h - 1, y2))

    if x2 <= x1 or y2 <= y1:
        return None
    return (x1, y1, x2, y2)


def main():
    if not os.path.exists(IMG_PATH):
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y ·∫£nh: {IMG_PATH}")
        return
    if not os.path.exists(ONNX_PATH):
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y model SixDRepNet: {ONNX_PATH}")
        return

    # 1) ƒê·ªçc ·∫£nh
    img = cv2.imread(IMG_PATH)
    if img is None:
        print("‚ùå cv2.imread tr·∫£ v·ªÅ None, check l·∫°i ƒë∆∞·ªùng d·∫´n ·∫£nh.")
        return

    # 2) D√≤ khu√¥n m·∫∑t ƒë·ªÉ l·∫•y bbox
    bbox = detect_face_bbox_mediapipe(img)
    if bbox is None:
        print("‚ùå Kh√¥ng ph√°t hi·ªán ƒë∆∞·ª£c khu√¥n m·∫∑t trong ·∫£nh.")
        return

    x1, y1, x2, y2 = bbox
    face = img[y1:y2, x1:x2]

    # 3) Load SixDRepNet
    print("üîπ ƒêang load SixDRepNet ONNX...")
    headpose_model = SixDRepONNX(path=ONNX_PATH)

    # 4) Suy lu·∫≠n head pose
    ypr = headpose_model.infer(face)
    if ypr is None:
        print("‚ùå Model tr·∫£ v·ªÅ None, kh√¥ng suy lu·∫≠n ƒë∆∞·ª£c t∆∞ th·∫ø ƒë·∫ßu.")
        return

    yaw, pitch, roll = ypr
    print(f"‚úÖ Head pose: yaw={yaw:.2f}, pitch={pitch:.2f}, roll={roll:.2f}")

    # 5) V·∫Ω bbox + tr·ª•c head pose
    vis = img.copy()
    cv2.rectangle(vis, (x1, y1), (x2, y2), (0, 255, 255), 2)

    # t√¢m khu√¥n m·∫∑t ƒë·ªÉ ƒë·∫∑t tr·ª•c
    cx = x1 + (x2 - x1) // 2
    cy = y1 + (y2 - y1) // 2

    # v·∫Ω 3 tr·ª•c X/Y/Z
    vis = draw_headpose_axes(vis, (cx, cy), yaw, pitch, roll, length=80)

    # v·∫Ω text g√≥c
    text = f"yaw={yaw:.1f}, pitch={pitch:.1f}, roll={roll:.1f}"
    cv2.putText(vis, text, (x1, max(20, y1 - 10)),
                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2, cv2.LINE_AA)

    # 6) L∆∞u ·∫£nh k·∫øt qu·∫£
    os.makedirs(os.path.dirname(OUT_PATH), exist_ok=True)
    cv2.imwrite(OUT_PATH, vis)
    print(f"üñº  ƒê√£ l∆∞u ·∫£nh demo head pose t·∫°i: {OUT_PATH}")


if __name__ == "__main__":
    main()
