# demo_gaze_image.py
import os, sys, cv2
import numpy as np

# Cho ph√©p import t·ª´ src/
sys.path.append(os.path.join(os.path.dirname(__file__), "src"))

from gaze_l2cs import L2CS, pick_providers
from facemesh_mediapipe import FaceMeshExtractor
from visualize_utils import draw_gaze_vector

# ===== CH·ªåN ·∫¢NH TRONG FOLDER data_test/sample_frames =====
IMG_DIR = "data_test/sample_frames"

def choose_image():
    files = [f for f in os.listdir(IMG_DIR) if f.lower().endswith((".jpg", ".png"))]
    if not files:
        print("‚ùå Kh√¥ng t√¨m th·∫•y ·∫£nh n√†o trong data_test/sample_frames/")
        exit()

    print("üîç Danh s√°ch ·∫£nh c√≥ th·ªÉ ch·ªçn:")
    for i, f in enumerate(files):
        print(f"   [{i}] {f}")

    idx = int(input("\nüëâ Nh·∫≠p s·ªë th·ª© t·ª± ·∫£nh mu·ªën demo: "))
    return os.path.join(IMG_DIR, files[idx])


def main():
    img_path = choose_image()
    print(f"\nüìå ƒêang x·ª≠ l√Ω ·∫£nh: {img_path}")

    # Load ·∫£nh
    img = cv2.imread(img_path)
    if img is None:
        print("‚ùå Kh√¥ng m·ªü ƒë∆∞·ª£c ·∫£nh!")
        return
    h, w = img.shape[:2]

    # Load model
    print("üîÑ Load L2CS-Net ONNX...")
    gaze_model = L2CS("models/l2cs_gaze.onnx", providers=pick_providers())

    print("üîÑ Kh·ªüi t·∫°o MediaPipe FaceMesh...")
    fm = FaceMeshExtractor(max_faces=1, refine_landmarks=True)

    # Face landmarks
    lm2d, _ = fm.extract(img)
    if lm2d is None:
        print("‚ùå Kh√¥ng t√¨m th·∫•y khu√¥n m·∫∑t trong ·∫£nh!")
        return

    # BBox quanh m·∫∑t
    x_min = int(np.min(lm2d[:, 0]))
    x_max = int(np.max(lm2d[:, 0]))
    y_min = int(np.min(lm2d[:, 1]))
    y_max = int(np.max(lm2d[:, 1]))

    pad_x = int(0.15 * (x_max - x_min))
    pad_y = int(0.25 * (y_max - y_min))

    x1 = max(0, x_min - pad_x)
    y1 = max(0, y_min - pad_y)
    x2 = min(w - 1, x_max + pad_x)
    y2 = min(h - 1, y_max + pad_y)

    face = img[y1:y2, x1:x2].copy()
    if face.size == 0:
        print("‚ùå Kh√¥ng crop ƒë∆∞·ª£c m·∫∑t!")
        return

    # Gaze estimation
    gaze = gaze_model.infer(face)
    if gaze is None:
        print("‚ùå L2CS kh√¥ng tr·∫£ ra k·∫øt qu·∫£!")
        return

    yaw, pitch = gaze
    print(f"üéØ Gaze Estimation ‚Üí yaw={yaw:.2f}, pitch={pitch:.2f}")

    # V·∫Ω vector √°nh nh√¨n
    cx = x1 + (x2 - x1) // 2
    cy = y1 + (y2 - y1) // 3

    cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 255), 2)
    draw_gaze_vector(img, (cx, cy), yaw, pitch, length=120)

    cv2.putText(img, f"yaw={yaw:.1f}, pitch={pitch:.1f}",
                (x1, max(15, y1 - 10)),
                cv2.FONT_HERSHEY_SIMPLEX, 0.7,
                (0, 255, 0), 2)

    # L∆∞u ·∫£nh k·∫øt qu·∫£
    os.makedirs("runs/gaze_demo", exist_ok=True)
    out_path = "runs/gaze_demo/output.jpg"
    cv2.imwrite(out_path, img)

    print(f"\n‚úÖ ƒê√£ l∆∞u ·∫£nh k·∫øt qu·∫£ t·∫°i: {out_path}")

    # Hi·ªÉn th·ªã
    cv2.imshow("Gaze Estimation - L2CS Demo", img)
    cv2.waitKey(0)
    cv2.destroyAllWindows()


if __name__ == "__main__":
    main()
